Metadata-Version: 2.4
Name: templatr
Version: 1.0.0
Summary: Local prompt optimizer with reusable templates and llama.cpp integration. No cloud, no API keys.
Author: Templatr Contributors
License: MIT
Project-URL: Homepage, https://github.com/josiahH-cf/templatr
Project-URL: Repository, https://github.com/josiahH-cf/templatr
Keywords: llm,prompt,templates,local,llama.cpp
Classifier: Development Status :: 5 - Production/Stable
Classifier: Environment :: X11 Applications :: Qt
Classifier: Intended Audience :: End Users/Desktop
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: POSIX :: Linux
Classifier: Operating System :: MacOS :: MacOS X
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Text Processing
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: PyQt6>=6.4.0
Requires-Dist: requests>=2.28.0
Requires-Dist: mistune<4.0,>=3.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0; extra == "dev"
Requires-Dist: pytest-qt>=4.2; extra == "dev"
Requires-Dist: black>=23.0; extra == "dev"
Requires-Dist: ruff>=0.1; extra == "dev"
Dynamic: license-file

# ü§ñ Templatr

**Create reusable AI prompts that run 100% on your computer.**

No cloud. No API keys. No subscriptions. Just you and your local AI.

![Templatr Screenshot](docs/screenshot.png)
<!-- TODO: Add screenshot showing the main window with a template -->

---

## ‚ú® What is Templatr?

Templatr helps you build **prompt templates** ‚Äî reusable prompts with fill-in-the-blank variables. Think of them like form letters for AI.

**Example:** Instead of retyping "Review this code for bugs..." every time, create a template once and reuse it forever.

### üîí Your Data Stays Private

Everything runs on your computer:
- ‚úÖ No internet connection required (after setup)
- ‚úÖ No accounts or sign-ups
- ‚úÖ Your prompts never leave your machine

---

## üöÄ Getting Started

### Step 1: Install

Open a terminal and run:

```bash
git clone https://github.com/josiahH-cf/templatr.git
cd templatr
./install.sh
```

This takes 5-10 minutes. It downloads and sets up everything automatically.

### Step 2: Get an AI Model

You need a `.gguf` model file ‚Äî this is the "brain" that generates responses.

1. Launch Templatr: `templatr`
2. Go to **LLM ‚Üí Download Models (Hugging Face)**
3. Download any model (start small, around 3-8GB)
4. Go to **LLM ‚Üí Select Model ‚Üí Add Model from File...**
5. Pick your downloaded `.gguf` file

**üí° Tip:** Smaller models run faster. Larger ones are smarter but slower.

### Step 3: Create Your First Template

1. Click **New Template**
2. Give it a name like "Code Review"
3. Write your prompt using `{{variables}}` for the blanks:
   ```
   Review this {{language}} code for bugs and improvements:
   
   {{code}}
   ```
4. Click **Save**

Now you can reuse this template anytime ‚Äî just fill in the blanks!

---

## üíª System Requirements

| Requirement | Minimum |
|-------------|---------|
| **OS** | Linux, macOS, or Windows (via WSL2) |
| **Python** | 3.10 or newer |
| **RAM** | 8GB (16GB recommended) |
| **Storage** | 10GB free for models |

---

## üóÇÔ∏è Where Files Are Stored

**Linux / WSL2:**
| What | Location |
|------|----------|
| Settings & Templates | `~/.config/templatr/` |
| LLM Server | `~/.local/share/templatr/` |
| Models | `~/models/` |

**macOS:**
| What | Location |
|------|----------|
| Settings & Templates | `~/Library/Application Support/templatr/` |
| Models | `~/models/` |

**To remove everything:**
```bash
# Linux/WSL2
rm -rf ~/.config/templatr/ ~/.local/share/templatr/ ~/models/*.gguf

# macOS  
rm -rf ~/Library/Application\ Support/templatr/ ~/models/*.gguf
```

---

## ‚ùì Common Questions

**Q: Do I need internet?**  
A: Only to download the app and a model. After that, everything works offline.

**Q: Is it free?**  
A: Yes, completely free and open source (MIT license).

**Q: What models work?**  
A: Any `.gguf` format model. Browse [Hugging Face](https://huggingface.co/models?search=gguf) for options.

**Q: It's slow. What can I do?**  
A: Use a smaller model, or upgrade your hardware. A GPU helps significantly.

**Q: Is there an Espanso integration?**
A: Espanso support lives in a separate project: [templatr-espanso](https://github.com/josiahH-cf/templatr-espanso).

---

## üìÑ License

MIT ‚Äî use it however you want.

---

<p align="center">
  Made with ‚ù§Ô∏è for people who value privacy
</p>
